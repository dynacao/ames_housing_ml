---
title: "ML Project"
subtitle: "Complementary Code"
author: "Daniel Choy, Yi Cao, Danny Zeng"
date: "Nov 10, 2020"
output:
  html_notebook:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Machine Learning Project - Ames Housing Data

Ames, Iowa is the college town of **Iowa State University**. The Ames housing dataset consists of about $2500$ house sale records between $2006-2010$. Detailed information about the house attributes, along with the sale prices, is recorded in the dataset. The goal of the project is to:
- perform descriptive data analysis to gain business (i.e. housing market) insights
- build descriptive machine learning models to understand the local housing market.
- build predictive machine learning models for the local house price prediction.


### Who We Are

Choose (but are not limited to) one of the following options:
- You are a housing market consultant.
- You are a data scientist for an online real estate database company which provides house price estimation (like **Zillow** home price estimates) for the site visitors.

The goal is to build a highly accurate predictive or descriptive model. To accomplish this, it is important to understand the local housing market in a **data driven** way. 

### Import Libraries

```{r, echo=False}
library(dplyr)
library(ggplot2)
library(lubridate)
library(tidyverse)
```

### Load Data

There are two data sets included in the data folder: Ames_Housing_Price_Data.csv and Ames_Real_Estate_Data.csv.

The Ames_Housing_Price_Data.csv set contains  81  data columns, including the key feature SalePrice which will be used as the target of the predictive/descriptive modeling. PID refers to the land parcel ID, which can merged on the MapRefNo column of the Ames Accessor Data (Ames_Real_Estate_Data.csv) to find the property address. Using a free service, such as geopy, we can find the long-lat coordinates of the houses.

The columns of the data are mostly attributes associated with the land and the houses. There are size related attributes, quality and condition attributes, house attachment attributes, etc.

```{r}
housing = read.csv('C:/Users/aznan/Data Science/ML with Python/ML_Project/Ames_HousePrice.csv', header = TRUE)
```

```{r}
real_estate = read.csv('C:/Users/aznan/Data Science/ML with Python/ML_Project/Ames Real Estate Data.csv')
```

## Data Pre-Processing

### Data Inspection
```{r}
str(housing)
```

### Data Cleaning

#### NA values - Dealing with Missing Data
```{r}
library(tidyverse)
# Remove NA values in MasVnrArea
housing1 = housing %>% 
  filter(is.na(MasVnrArea) != 1)
```

```{r}
# Remove NA values in TotalBsmtSF
housing2 = housing1 %>% 
  filter(is.na(TotalBsmtSF) != 1)
```



#### Mutate Columns
```{r}
library(car)

# Create new columns for better modeling 
housing3 = housing2 %>% 
  filter(is.na(MasVnrArea) != 1) %>% 
  mutate(
    
    MasVnrArea2 = case_when(
      MasVnrArea == 0 ~ 0,
      MasVnrArea != 0 ~ 1),
    
    GarageArea2 = ifelse(is.na(GarageArea), 0, GarageArea),
    
    PoolArea2 = ifelse(is.na(PoolArea), 0, PoolArea),
    
    PoolArea3 = ifelse(is.na(PoolArea), 0, 1),
    
    X2ndFlrSF = ifelse(is.na(X2ndFlrSF), 0, X2ndFlrSF),
    
    HalfBath2 = case_when(
      HalfBath == 1 ~ 0.5,
      HalfBath == 0 ~ 0),
    
    BsmtHalfBath2 = case_when(
      BsmtHalfBath == 1 ~ 0.5,
      BsmtHalfBath == 0 ~ 0),
    # If Basement Finish Type1 is GLQ or ALQ, we use the Basement Finish Square Feet1
    BasmtFinSF1 = ifelse(BsmtFinType1 == 'GLQ' | BsmtFinType1 == 'ALQ', BsmtFinSF1, 0),
    # If Basement Finish Type2 is GLQ or ALQ, we use the Basement Finish Square Feet2
    BasmtFinSF2 = ifelse(BsmtFinType2 == 'GLQ' | BsmtFinType2 =='ALQ', BsmtFinSF2, 0),
    # The Total Square Feet of Basement Finish is BasmtFinSF1 + BasmtFinSF2
    BasmtFinSF = BasmtFinSF1 + BasmtFinSF2,
    # Total Living Area is GrLivArea + BasmtFinSF
    total_LivArea = GrLivArea + BasmtFinSF,
    num_bathroom = BsmtHalfBath2 + HalfBath2 + FullBath + BsmtFullBath
  )

# Final Data set after cleaning

housing_df = housing3
```




### Data Type



## Exploratory Data Analysis












## Model Selection


### Model 1: Base Model
```{r}
# Basic model - starting line
housing.model = lm(log(SalePrice) ~ log(GrLivArea) + LotArea + MasVnrArea, data = housing_df)
summary(housing.model)
plot(housing.model)
```

### Model 2
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2
```{r}
housing.model2 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2, data = housing_df)
summary(housing.model2)
plot(housing.model2)
vif(housing.model2)
```


### Model 3
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2, log(TotalBsmtSF + 1)
```{r}
housing.model3 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1), data = housing_df)
summary(housing.model3)
plot(housing.model3)
vif(housing.model3)
```


### Model 4
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2, log(TotalBsmtSF + 1), log(GarageArea2 + 1)
```{r}
housing.model4 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1),  data = housing_df)
summary(housing.model4)
vif(housing.model4)
plot(housing.model4)
```



### Model 5
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2, log(TotalBsmtSF + 1), log(GarageArea2 + 1), log(PoolArea + 1)
```{r}
housing.model5 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + log(PoolArea + 1),  data = housing_df)
summary(housing.model5)
vif(housing.model5)
plot(housing.model5)
```


### Model 6
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2, log(TotalBsmtSF + 1), log(GarageArea2 + 1), PoolArea
```{r}
housing.model6 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + PoolArea,  data = housing_df)
summary(housing.model6)
vif(housing.model6)
plot(housing.model6)
```

```{r}
# Check linear regression between SalePrice and PoolArea
pool.model = lm(SalePrice ~ PoolArea, data = housing)
summary(pool.model)
# Get rid of PoolArea
```

```{r}
# Check linear regression between SalePrice and YearBuilt, YearRemodAdd
year.model = lm(SalePrice ~ YearBuilt + YearRemodAdd, data = housing4)
summary(year.model)
vif(year.model)
summary(housing4)
# Year Built and Year Remodeled are significant variables to add
```


### Model 7
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2, log(TotalBsmtSF + 1), log(GarageArea2 + 1), YearBuilt, YearRemodAdd
```{r}
housing.model7 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + YearBuilt + YearRemodAdd,  data = housing_df)

summary(housing.model7)
plot(housing.model7)
```

```{r}
anova(housing.model7, housing.model6, test = 'Chisq')
```
We reject the null hypothesis and conclude that adding more features in the model should provide a better fit. In other words, the full model is better than the reduced model.


### *Checking Models
```{r}
# Check linear regression between SalePrice and MoSold, YrSold
sold.model = lm(SalePrice ~ MoSold + YrSold, data = housing_df)
summary(sold.model)
plot(sold.model)
# Month and Year sold - irrelevant
```

```{r}
# Check linear regression between SalePrice and OverallQual, OverallCond
quality.model = lm(SalePrice ~ OverallQual + OverallCond, housing_df)
summary(quality.model)
plot(quality.model)
```



### Model 8
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2, log(TotalBsmtSF + 1), log(GarageArea2 + 1), YearBuilt, YearRemodAdd, OverallQual, OverallCond
```{r}
housing.model8 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + YearBuilt + YearRemodAdd + OverallQual + OverallCond,  data = housing_df)
summary(housing.model8)
plot(housing.model8)
```

```{r}
anova(housing.model8, housing.model7, test = 'Chisq')
# Multiple R-Squared too lage?
```



### Model 9
Independent Variables: log(GrLivArea), log(LotArea), MasVnrArea2, log(TotalBsmtSF + 1), log(GarageArea2 + 1), YearBuilt, YearRemodAdd, OverallQual, OverallCond, og(X1stFlrSF), log(X2ndFlrSF + 1)
```{r}
housing.model9 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + YearBuilt + YearRemodAdd + OverallQual + log(X1stFlrSF) + log(X2ndFlrSF + 1),  data = housing_df)
summary(housing.model9)
plot(housing.model9)
```

```{r}
anova(housing.model12, housing.model11, test = 'Chisq')
vif(housing.model12)
# Multicolinearity - Remove 1stFlrSF and 2ndFlrSF
```


### Model 10 - 11

1. Model with Total Number of Rooms (Including the Basement) 
```{r}
# Model with GrLivArea
housing.model10 = lm(log(SalePrice) ~ log(GrLivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + YearBuilt + YearRemodAdd + OverallQual, data = housing_df)
summary(housing.model10)
vif(housing.model10)

# Model with total_room
housing.model11 = lm(log(SalePrice) ~ log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + YearBuilt + YearRemodAdd + OverallQual + total_room, data = housing_df)
summary(housing.model14)
vif(housing.model14)

# Note: total_room initially had a big p-value. Possibly a mulitcolinearity issue with log(GrLivArea). When we took out log(GrLivArea), we get a small p-value for total_room
```

2. Model with Number of bathrooms (just the bathrooms, including the Basement & Full Bath & HalfBath) 
```{r}
# Total_LivArea
housing.model15 = lm(log(SalePrice) ~ log(total_LivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + YearBuilt + YearRemodAdd + OverallQual, data = housing7)
summary(housing.model15)
vif(housing.model15)

housing.model16 = lm(log(SalePrice) ~ log(total_LivArea) + log(LotArea) + MasVnrArea2 + log(TotalBsmtSF + 1) + log(GarageArea2 + 1) + YearBuilt + YearRemodAdd + OverallQual + num_bathroom, data = housing7)
summary(housing.model16)
vif(housing.model16)
# Overfitting - dont include number of bathroom


```

3. Model with Number of bedrooms
```{r}


```






## Descriptive Modeling




## Predictive Modeling







